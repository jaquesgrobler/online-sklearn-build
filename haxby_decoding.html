


<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>NiLearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="index.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0;">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">

<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="index.html">
      <img src="_static/nilearn-logo.png" alt="NiLearn logo"  border="0" />
    </a>
  </div>
  <div class="banner">
    <h1>NiLearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
<li><a href="index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/classes.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="AUTHORS.html#citing">citing the
                    scikit-learn</a> if you use it.</p></li>
  </ul>

  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.2. fMRI decoding: predicting which object a subject is viewing</a><ul>
<li><a class="reference internal" href="#data-loading-and-preprocessing">4.2.1. Data loading and preprocessing</a></li>
<li><a class="reference internal" href="#down-to-business-decoding-analysis">4.2.2. Down to business: decoding analysis</a><ul>
<li><a class="reference internal" href="#prediction-function-the-estimator">4.2.2.1. Prediction function: the estimator</a></li>
<li><a class="reference internal" href="#dimension-reduction">4.2.2.2. Dimension reduction</a></li>
<li><a class="reference internal" href="#launching-it-on-real-data-fit-train-and-predict-test">4.2.2.3. Launching it on real data: fit (train) and predict (test)</a></li>
<li><a class="reference internal" href="#visualising-the-results">4.2.2.4. Visualising the results</a></li>
<li><a class="reference internal" href="#cross-validation-measuring-prediction-performance">4.2.2.5. Cross-validation: measuring prediction performance</a></li>
</ul>
</li>
<li><a class="reference internal" href="#going-further-with-scikit-learn">4.2.3. Going further with scikit-learn</a><ul>
<li><a class="reference internal" href="#changing-the-prediction-function">4.2.3.1. Changing the prediction function</a></li>
<li><a class="reference internal" href="#changing-the-feature-selection">4.2.3.2. Changing the feature selection</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="fmri-decoding-predicting-which-object-a-subject-is-viewing">
<span id="fmri-decoding"></span><h1>4.2. fMRI decoding: predicting which object a subject is viewing<a class="headerlink" href="#fmri-decoding-predicting-which-object-a-subject-is-viewing" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first">Objectives</p>
<p>At the end of this tutorial you will be able to:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Load fMRI volumes in Python.</li>
<li>Perform a state-of-the-art decoding analysis of fMRI data.</li>
<li>Perform even more sophisticated analyses of fMRI data.</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="data-loading-and-preprocessing">
<h2>4.2.1. Data loading and preprocessing<a class="headerlink" href="#data-loading-and-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>Launch ipython:</p>
<div class="highlight-python"><pre>$ ipython -pylab</pre>
</div>
<p>First, load the data using the tutorial&#8217;s data downloader,
<a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby_simple.html#nilearn.datasets.fetch_haxby_simple" title="nilearn.datasets.fetch_haxby_simple"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.datasets.fetch_haxby_simple</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nibabel</span>
<span class="n">dataset_files</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby_simple</span><span class="p">()</span>

<span class="c"># fmri_data and mask are copied to break any reference to the original object</span>
<span class="n">bold_img</span> <span class="o">=</span> <span class="n">nibabel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">dataset_files</span><span class="o">.</span><span class="n">func</span><span class="p">)</span>
<span class="n">fmri_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">bold_img</span><span class="o">.</span><span class="n">get_data</span><span class="p">())</span>
<span class="n">affine</span> <span class="o">=</span> <span class="n">bold_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()</span>
<span class="n">y</span><span class="p">,</span> <span class="n">session</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">dataset_files</span><span class="o">.</span><span class="n">session_target</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&quot;int&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">recfromtxt</span><span class="p">(</span><span class="n">dataset_files</span><span class="o">.</span><span class="n">conditions_target</span><span class="p">)[</span><span class="s">&#39;f0&#39;</span><span class="p">]</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">dataset_files</span><span class="o">.</span><span class="n">mask</span>
<span class="c"># fmri_data.shape is (40, 64, 64, 1452)</span>
<span class="c"># and mask.shape is (40, 64, 64)</span>
</pre></div>
</div>
<p>Then preprocess the data:</p>
<ul class="simple">
<li>compute the mean of the image to replace anatomic data</li>
<li>mask data X and transpose the matrix, so that its shape becomes
(n_samples, n_features) (see <a class="reference internal" href="dataset_manipulation.html#mask-4d-2-3d"><em>From 4D to 2D arrays</em></a> for a discussion on using
masks)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Build the mean image because we have no anatomic data</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">fmri_data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="green topic">
<p class="topic-title first"><strong>Exercise</strong></p>
<ol class="arabic simple">
<li>Extract the period of activity from the data (i.e. remove the remainder).</li>
</ol>
</div>
<div class="topic">
<p class="topic-title first">Solution</p>
<p>As &#8216;y == 0&#8217; in rest, we want to keep only time points for which
<cite>y != 0</cite>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">session</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">],</span> <span class="n">session</span><span class="p">[</span><span class="n">y</span><span class="o">!=</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Here, we limit our analysis to the <cite>face</cite> and <cite>house</cite> conditions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Keep only data corresponding to faces or houses</span>
<span class="n">condition_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">conditions</span> <span class="o">==</span> <span class="s">&#39;face&#39;</span><span class="p">,</span> <span class="n">conditions</span> <span class="o">==</span> <span class="s">&#39;house&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">fmri_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">condition_mask</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">session</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="n">conditions</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>

<span class="c"># We have 2 conditions</span>
<span class="n">n_conditions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c">### Loading step ##############################################################</span>
<span class="kn">from</span> <span class="nn">nilearn.input_data</span> <span class="kn">import</span> <span class="n">NiftiMasker</span>
<span class="kn">from</span> <span class="nn">nibabel</span> <span class="kn">import</span> <span class="n">Nifti1Image</span>
<span class="n">nifti_masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">sessions</span><span class="o">=</span><span class="n">session</span><span class="p">,</span> <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                           <span class="n">memory</span><span class="o">=</span><span class="s">&quot;nilearn_cache&quot;</span><span class="p">,</span> <span class="n">memory_level</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">niimg</span> <span class="o">=</span> <span class="n">Nifti1Image</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">affine</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">niimg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="down-to-business-decoding-analysis">
<h2>4.2.2. Down to business: decoding analysis<a class="headerlink" href="#down-to-business-decoding-analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prediction-function-the-estimator">
<h3>4.2.2.1. Prediction function: the estimator<a class="headerlink" href="#prediction-function-the-estimator" title="Permalink to this headline">¶</a></h3>
<p>To perform decoding we construct an estimator, predicting a condition
label <strong>y</strong> given a set <strong>X</strong> of images.</p>
<p>We define here a simple <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html">Support Vector Classification</a> (or SVC) with C=1, and a
linear kernel. We first import the correct module from scikit-learn and we
define the classifier:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Define the prediction function to be used.</span>
<span class="c"># Here we use a Support Vector Classification, with a linear kernel and C=1</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
<p>Need some doc ?</p>
<div class="highlight-python"><pre>&gt;&gt;&gt; clf ? 
Type:             SVC
Base Class:       &lt;class 'sklearn.svm.libsvm.SVC'&gt;
String Form:
SVC(kernel=linear, C=1.0, probability=False, degree=3, coef0=0.0, eps=0.001,
cache_size=100.0, shrinking=True, gamma=0.0)
Namespace:        Interactive
Docstring:
    C-Support Vector Classification.
    Parameters
    ----------
    C : float, optional (default=1.0)
        penalty parameter C of the error term.
...</pre>
</div>
<p>Or go to the <a class="reference external" href="http://scikit-learn.org/modules/svm.html">scikit-learn
documentation</a>
We use a SVC here, but we can use
<a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">many other
classifiers</a></p>
</div>
<div class="section" id="dimension-reduction">
<h3>4.2.2.2. Dimension reduction<a class="headerlink" href="#dimension-reduction" title="Permalink to this headline">¶</a></h3>
<p>As there are a very large number of voxels and not all are useful for
face vs house prediction, we add a <a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html">feature selection</a>
procedure. The idea is to select the <cite>k</cite> voxels most correlated to the
task.</p>
<p>For this, we need to import the correct module and define a simple F-score
based feature selection (a.k.a.
<a class="reference external" href="http://en.wikipedia.org/wiki/Analysis_of_variance#The_F-test">Anova</a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="c">### Define the dimension reduction to be used.</span>
<span class="c"># Here we use a classical univariate feature selection based on F-test,</span>
<span class="c"># namely Anova. We set the number of features to be selected to 500</span>
<span class="n">feature_selection</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c"># We have our classifier (SVC), our feature selection (SelectKBest), and now,</span>
<span class="c"># we can plug them together in a *pipeline* that performs the two operations</span>
<span class="c"># successively:</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">anova_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="section" id="launching-it-on-real-data-fit-train-and-predict-test">
<h3>4.2.2.3. Launching it on real data: fit (train) and predict (test)<a class="headerlink" href="#launching-it-on-real-data-fit-train-and-predict-test" title="Permalink to this headline">¶</a></h3>
<p>In scikit-learn, the prediction objects (classifiers, regression) have a very simple API:</p>
<ul class="simple">
<li>a <em>fit</em> function that &#8220;learns&#8221; the parameters of the model from the data.
Thus, we need to give some training data to <em>fit</em>.</li>
<li>a <em>predict</em> function that &#8220;predicts&#8221; a target from new data.
Here, we just have to give the new set of images (as the target should be
unknown):</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">anova_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">anova_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Warning ! Do not do this at home:</strong> the prediction that we obtain here
is to good to be true (see next paragraph). Here we are just doing a
sanity check.</p>
</div>
<div class="section" id="visualising-the-results">
<h3>4.2.2.4. Visualising the results<a class="headerlink" href="#visualising-the-results" title="Permalink to this headline">¶</a></h3>
<p>We can visualize the result of our algorithm:</p>
<ul class="simple">
<li>we first get the support vectors of the SVC and revert the feature
selection mechanism</li>
<li>we remove the mask</li>
<li>then we overlay our previously-computed, mean image with our support vectors</li>
</ul>
<div class="figure align-center">
<a class="reference external image-reference" href="auto_examples/plot_haxby_decoding.html"><img alt="_images/plot_haxby_decoding_1.png" src="_images/plot_haxby_decoding_1.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Look at the discriminating weights</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span>
<span class="c"># reverse feature selection</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">feature_selection</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
<span class="c"># reverse masking</span>
<span class="n">niimg</span> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>

<span class="c"># We use a masked array so that the voxels at &#39;-1&#39; are displayed</span>
<span class="c"># transparently</span>
<span class="n">act</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">niimg</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span> <span class="n">niimg</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>

<span class="c">### Create the figure</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">pl</span>
<span class="n">pl</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">&#39;off&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;SVM vectors&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">mean_img</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">27</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">,</span>
          <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">act</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">hot</span><span class="p">,</span>
          <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c"># Saving the results as a Nifti file may also be important</span>
<span class="kn">import</span> <span class="nn">nibabel</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">affine</span><span class="p">)</span>
<span class="n">nibabel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s">&#39;haxby_face_vs_house.nii&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="cross-validation-measuring-prediction-performance">
<h3>4.2.2.5. Cross-validation: measuring prediction performance<a class="headerlink" href="#cross-validation-measuring-prediction-performance" title="Permalink to this headline">¶</a></h3>
<p>However, the last analysis is <em>wrong</em>, as we have learned and tested on
the same set of data. We need to use a cross-validation to split the data
into different sets.</p>
<p>In scikit-learn, a cross-validation is simply a function that generates
the indices of the folds within a loop.
Now, we can apply the previously defined <em>pipeline</em> with the
cross-validation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">LeaveOneLabelOut</span>

<span class="c">### Define the cross-validation scheme used for validation.</span>
<span class="c"># Here we use a LeaveOneLabelOut cross-validation on the session label</span>
<span class="c"># divided by 2, which corresponds to a leave-two-session-out</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">LeaveOneLabelOut</span><span class="p">(</span><span class="n">session</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>

<span class="c">### Compute the prediction accuracy for the different folds (i.e. session)</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">anova_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span> \
        <span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])))</span>
</pre></div>
</div>
<p>But we are lazy people, so there is a specific
function, <em>cross_val_score</em> that computes for you the results for the
different folds of cross-validation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
</pre></div>
</div>
<p>If you are the happy owner of a multiple-processor computer you can
speed up the computation by using n_jobs=-1, which will spread the
computation equally across all processors (but will probably not work
under Windows):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> 
</pre></div>
</div>
<p><strong>Prediction accuracy</strong> We can take a look at the results of the
<em>cross_val_score</em> function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> 
<span class="go">array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,</span>
<span class="go">        1.        ,  1.        ,  0.94444444,  1.        ,  1.        ,</span>
<span class="go">        1.        ,  1.        ])</span>
</pre></div>
</div>
<p>This is simply the prediction score for each fold, i.e. the fraction of
correct predictions on the left-out data.</p>
<div class="green topic">
<p class="topic-title first"><strong>Exercise</strong></p>
<ol class="arabic simple">
<li>Compute the mean prediction accuracy using <em>cv_scores</em></li>
</ol>
</div>
<div class="topic">
<p class="topic-title first">Solution</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> 
<span class="go">0.99537037037037035</span>
</pre></div>
</div>
</div>
<p>We have a total prediction accuracy of 99% across the different folds.</p>
<p>We can add a line to print the results:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Return the corresponding mean prediction accuracy</span>
<span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>

<span class="c">### Printing the results</span>
<span class="k">print</span> <span class="s">&quot;=== ANOVA ===&quot;</span>
<span class="k">print</span> <span class="s">&quot;Classification accuracy: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">classification_accuracy</span><span class="p">,</span> \
    <span class="s">&quot; / Chance level: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n_conditions</span><span class="p">)</span>
<span class="c"># Classification accuracy: 0.986111  / Chance level: 0.500000</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Final script</p>
<p>The complete script can be found as
<em class="xref std std-ref">an example</em>.
Now, all you have to do is publish the results :)</p>
</div>
</div>
</div>
<div class="section" id="going-further-with-scikit-learn">
<h2>4.2.3. Going further with scikit-learn<a class="headerlink" href="#going-further-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<p>We have seen a very simple analysis with scikit-learn, but it may be
interesting to explore the <a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">wide variety of supervised learning
algorithms in the scikit-learn</a>.</p>
<div class="section" id="changing-the-prediction-function">
<h3>4.2.3.1. Changing the prediction function<a class="headerlink" href="#changing-the-prediction-function" title="Permalink to this headline">¶</a></h3>
<p>We now see how one can easily change the prediction function, if needed.
We can try the <a class="reference external" href="http://scikit-learn.org/auto_examples/plot_lda_qda.html">Linear Discriminant Analysis (LDA)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.lda</span> <span class="kn">import</span> <span class="n">LDA</span>
</pre></div>
</div>
<p>Construct the new prediction function and use it in a pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anova_lda</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;LDA&#39;</span><span class="p">,</span> <span class="n">lda</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_lda</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s">&quot;Classification accuracy: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">classification_accuracy</span><span class="p">,</span> \
<span class="gp">... </span>    <span class="s">&quot; / Chance level: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n_conditions</span><span class="p">)</span> 
<span class="go">Classification accuracy: 1.000000   / Chance level: 0.500000</span>
</pre></div>
</div>
</div>
<div class="section" id="changing-the-feature-selection">
<h3>4.2.3.2. Changing the feature selection<a class="headerlink" href="#changing-the-feature-selection" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s say that you want a more sophisticated feature selection, for example a
<a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination">Recursive Feature Elimination (RFE)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
</pre></div>
</div>
<p>Construct your new fancy selection:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.</span><span class="p">),</span> <span class="mi">50</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>
</div>
<p>and create a new pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;rfe&#39;</span><span class="p">,</span> <span class="n">rfe</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rfe_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
</pre></div>
</div>
<p>But, be aware that this can take A WHILE...</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
<li><a href="index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/classes.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
    <div class="footer">
            &copy; INRIA Parietal 2010-2013.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2.
        <span style="padding-left: 5ex;">
          <a href="_sources/haxby_decoding.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>